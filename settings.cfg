#*~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~*#
#*     COFFE parameter file     *#
#*~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~*#


###############
#(1): Input  #
###############

### (1.a)
# file containing the separations for which the
# correlation function is computed (not needed if "output_type" is 0, 4, 5, 6)
# NOTE: separations must be in units Mpc/h

input_separations = "separations.dat";

### (1.b)
# file containing the power spectrum
# NOTE: file containing spectrum must have two columns;
# allowed separators are ' ', ',', '\t' (tabs), or ':';
# k must be in h/Mpc, and P(k) must be in (Mpc/h)^3

input_power_spectrum = "PkL_CLASS.dat";

# should the power spectrum be windowed by a real-space spherical top hat?
# possible values: int: 0, 1
have_window = 0

# if have_window is set to 1, the size of the window (in Mpc/h)
# possible values: double x: x>0, x<1000
window_size = 5

### (1.c)
# cold dark matter density, baryon density, and radiation density parameter
# NOTE: dark energy density parameter is computed from
# the closure relation sum(Omega) + Omega(DE) = 1

omega_cdm = 0.25;
omega_baryon = 0.05;
omega_gamma = 9e-5;


### (1.d)
# equation of state for dark energy, parametrised as w(z) = w0 + wa z/(1+z)

w0 = -1.0;
wa = 0.0;

### (1.e)
# galaxy bias, magnification bias and evolution bias
# either a constant value or read a file containing the bias as a function of redshift (in ascending redshift)
# "1" and "2" label the galaxies populations

# should COFFE use an analytic formula (defined by the function `coffe_galaxy_bias`) for the bias or not?
# possible values: int: 0 (no), 1 (yes)
# default: 0
matter_bias_analytic = 0;

matter_bias1 = 1.;
read_matter_bias1 = 0;
input_matter_bias1 = "";

matter_bias2 = 1.;
read_matter_bias2 = 0;
input_matter_bias2 = "";

magnification_bias1 = 0.;
read_magnification_bias1 = 0;
input_magnification_bias1 = "";

magnification_bias2 = 0.;
read_magnification_bias2 = 0;
input_magnification_bias2 = "";

evolution_bias1 = 0.;
read_evolution_bias1 = 0;
input_evolution_bias1 = "";

evolution_bias2 = 0.;
read_evolution_bias2 = 0;
input_evolution_bias2 = "";

### (1.f)
# parameter for the covariance
# respectively: the pixel size (in Mpc/h), the mean number density at z_mean (in (h/Mpc)^3) and the sky coverage of the catalog

covariance_z_mean = [0.5, 1.0, 1.5];
covariance_deltaz = [0.1, 0.1, 0.2];
covariance_density = [0.1, 0.2, 0.01];
covariance_fsky = [0.3, 0.5, 0.2];
covariance_pixelsize = 10.0;

covariance_zmin = [2.0, 2.2, 2.3];
covariance_zmax = [2.5, 2.8, 2.5];

# minimum separation for the covariance (in Mpc/h)
# can be different from pixelsize
# default: 20.0
covariance_minimum_separation = 20.0

# how should COFFE compute the covariance?
# possible values:
# 1 - GSL integration
# 2 - 2D FFT log integration (described in arXiv:2004.04833)
# default: 1
covariance_integration_method = 1

# if the integration method is FFT log, this specifies how many points to use
# N.B. the memory usage and run time is proportional to the below squared,
# so with ~10^4 bins, you need to have at least 5 GB of RAM available
# since one needs at least 10000^2 x 8 / 1024^2 MB ~ 750 MB
# to just store the result (not including the space for interpolating it)
covariance_integration_bins = 8000

# if using FFT log, the method for 2D interpolating the covariance
# possible values:
# 1 - bilinear
# 2 - bicubic
# default: 2
covariance_interpolation_method = 2


###############
#(2): Output  #
###############

### (2.a)
# the relative or absolute path of output; if directory doesn't exist, COFFE will try to create it
# a prefix can be appended to the standard outputs; if it's "$TIME", then it appends the timestamp
# in the format "YYYY-MM-DD-HH-mm-ss_". Note that COFFE may overwrite previous results, it is up to the user
# to make sure the path doesn't already exist!

output_path = "results/";

output_prefix = "$TIME";

### (2.b)
# which projection effect to take into account (see 1708.00492 for details), possible values are:
# rsd = redshift space distortion
# den = density
# d1, d2 = nonintegrated doppler terms
# g1, g2, g3 = nonintegrated gravitational potential terms
# g4, g5 = integrated gravitational potential terms
# len = integrated lensing term
# NOTE: the correlation calculated for types A and B is automatically A*A + A*B + B*A + B*B
# default: ["den"]

correlation_contributions = ["den"];

### (2.c)
# for output - specify if you want:
# (see the User guide for details)
# (0) angular correlation function
# (1) correlation function as function of mean redshift, angles, and separation
# (2) multipoles as function of l, mean redshift, and separation
# (3) average multipoles as function of l and separation
# (4) covariance of multipoles
# (5) covariance of redshift averaged multipoles
# (6) 2D correlation function as a function of r_parallel and r_perpendicular

output_type = 2;

### (2.d)
# if output_type is not 3, the mean redshift for which to calculate the output

z_mean = 1.0;

### (2.e)
# the thickness of the redshift bin for which we calculate
# the output; cannot be negative or larger than z_mean for obvious reasons

deltaz = 0.2;

z_min = 0.9;
z_max = 1.1;

### (2.f)
# needed if output_type = 1

mu = [0.7];

### (2.g)
# needed if output_type = 2, 3, 4 or 5
# multipoles you want to compute: 0=monopole, 2=quadrupole, 4=hexadecapole, 6=tetrahexadecapole, etc.

multipoles = [0, 2, 4];

### (2.h)
# optional: which background quantities to output; possible values are:
# z = redshift
# a = scale factor
# H = Hubble rate
# conformal_H = conformal Hubble rate
# conformal_H_prime = derivative of conformal Hubble rate w.r.t. conformal time
# D1 = growth function
# f = derivative d(ln D1)/d(ln a)
# comoving_distance
# NOTE: they will be written into the file in the same order as given here

output_background = ["z", "a", "H", "conformal_H", "conformal_H_prime", "D1", "f", "comoving_distance"];

### (2.i)
# should the contributions be computed using the flatsky approximation?
# possible values: int: 0 (no), 1 (yes)
# default: 0

# for density-lensing + lensing-density
flatsky_density_lensing = 0;
# for lensing-lensing
flatsky_lensing_lensing = 0;
# for density-density + density-rsd + rsd-density + rsd-rsd
flatsky_standard_standard = 0;

###########################
#(3): Precision settings  #
###########################

### (3.a)
# the sampling rate for the background; about 1 second to sample 10000 points

background_sampling = 10000;

### (3.b)
# for how many points to compute the integral of P(k) k^2 j_l(kr) (NOTE: runtime is <1 s for 10000 points)

bessel_sampling = 10000;

### (3.c)
# the sampling for the angular correlation function (between 0 and pi/2)

theta_sampling = 3000;

### (3.d)
# double integrated terms are computed using monte carlo methods from GSL;
# the available methods are:
# 0 - standard random sampling
# 1 - MISER algorithm of Press and Farrar; based on recursive stratified sampling
# 2 - VEGAS algorithm of Lepage; based on importance sampling
# NOTE: if CUBA is used, only the integration_len parameter is needed
# reference: about 60000 for correlation function,
# 300000 for multipoles, more for redshift-averaged multipoles

integration_method = 2;
integration_sampling = 750000;

### (3.e)
# optional: the range of integration for the integral
# over the power spectrum
# NOTE: the range should be -smaller- than the one
# read from the file, otherwise the range from the file
# will be used instead
# NOTE: must be in h/Mpc

k_min = 1e-5;
k_max = 300.;

### (3.f)
# the interpolation type for all interpolation variables
# possible values (taken from GSL v2.4 manual):
# 1 - linear
# 2 - polynomial
# 3 - cubic spline with natural boundary conditions
# 4 - cubic spline with periodic boundary conditions
# 5 - non-rounded Akima spline with natural boundary conditions
# 6 - non-rounded Akima spline with periodic boundary conditions
# 7 - monotone cubic spline, described in: 
# M. Steffen, A simple method for monotonic interpolation in one dimension, Astron. Astrophys. 239, 443-450, 1990.

interpolation = 5;

### (4.a)
# should CLASS be used on the fly to generate the linear matter power spectrum? 1 for yes, 0 for no
# NOTE: CLASS MUST be linked at compile time, otherwise this has no effect!
have_class = 0;

# Hubble constant divided by 100
h = 0.67;

# pivot scale of the dimensionless scalar primordial power spectrum, in 1/Mpc
k_pivot = 0.05;

# ln (10^{10} A_s), where A_s is the amplitude of the dimensionless scalar primordial power spectrum
ln_10_pow_10_A_s = 3.06;

# spectral index of the dimensionless scalar primordial power spectrum
n_s = 0.96;

# should the output be verbose or not?
# possible values:
# 0 - only errors and warning are displayed
# 1 - reports what is being calculated and the time taken, as well as where the output is saved
verbose = 1

# should we use CLASS to generate matter power spectrum on-the-fly?
# 0 - do not generate the matter power spectrum on-the-fly
# 1 - use linear theory matter power spectrum
# 2 - use halofit model of the matter power spectrum
# 3 - use hmcode model of the matter power spectrum
# default: 0
pk_type = 0

zeldovich_approximation = 0
